{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "346a059f",
   "metadata": {
    "id": "346a059f"
   },
   "source": [
    "## 1.1. Load dataset\n",
    "#### You will need to read the data from the file (cover.csv). It contains 581012 samples and 54 attributes for each sample. The target column is Cover_Type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21910fe9",
   "metadata": {
    "id": "21910fe9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "data = pd.read_csv('cover.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452f1f9e",
   "metadata": {
    "id": "452f1f9e"
   },
   "source": [
    "# 1. Voting Classifier\n",
    "#### In this assignment, you are expected to build an ensemble of different models and train it on cover type dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5736593",
   "metadata": {
    "id": "a5736593"
   },
   "source": [
    "## 1.2. Prepare dataset\n",
    "#### Split the data into train, validation, and test sets using train_test_split twice with 0.2 test_size. Your final distribution will be 371847-92962-116203."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b0ad4",
   "metadata": {
    "id": "622b0ad4"
   },
   "outputs": [],
   "source": [
    "X = data.drop('Cover_Type', axis=1)\n",
    "y = data['Cover_Type']\n",
    "\n",
    "# Splitting dataset\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_temp, y_train_temp, test_size=0.2, random_state=42, stratify=y_train_temp\n",
    ")\n",
    "\n",
    "# Scalin dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "y_train_adjusted = y_train - 1\n",
    "y_val_adjusted = y_val - 1\n",
    "y_test_adjusted = y_test - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae3e4b3",
   "metadata": {
    "id": "4ae3e4b3"
   },
   "source": [
    "## 1.3. Modeling\n",
    "#### Train 4-5 different classifiers on the data. You can train RandomForestClassifier, ExtraTreesClassifier, LinearSVC, SGDClassifier, MLPClassifier, etc. Evaluate their performances using validation set. Note that training may take quite a while (up to 30 minutes) depending on the hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9VogfRiYJsZd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9VogfRiYJsZd",
    "outputId": "17484819-22b9-4303-d236-8011b5078fa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9499580473741959\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "clf1 = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "clf1.fit(X_train, y_train)\n",
    "rf_preds = clf1.predict(X_val)\n",
    "rf_acc = accuracy_score(y_val, rf_preds)\n",
    "print(f'Random Forest Accuracy: {rf_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ckjA6ftbJ00R",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ckjA6ftbJ00R",
    "outputId": "9068944d-99d1-4d01-82af-e590c2aa7813"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 0.712269529485166\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Classifier\n",
    "clf3 = LinearSVC(random_state=42, max_iter=20000, C=1)\n",
    "clf3.fit(X_train_scaled, y_train)  # requires scaled data\n",
    "svc_preds = clf3.predict(X_val_scaled)\n",
    "svc_acc = accuracy_score(y_val, svc_preds)\n",
    "print(f'SVC Accuracy: {svc_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dSl9v-qFO-8r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dSl9v-qFO-8r",
    "outputId": "96383cd5-7b5b-4570-8946-82a3bea51add"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier Accuracy: 0.7150233428712808\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier\n",
    "clf4 = SGDClassifier(random_state=42, max_iter=2000, alpha=0.0001, loss='log_loss') # Changed loss to 'log_loss'\n",
    "clf4.fit(X_train_scaled, y_train)  # requires scaled data\n",
    "sgd_preds = clf4.predict(X_val_scaled)\n",
    "sgd_acc = accuracy_score(y_val, sgd_preds)\n",
    "print(f'SGD Classifier Accuracy: {sgd_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7toEGDqqJ5Hh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7toEGDqqJ5Hh",
    "outputId": "78e618c4-4d7d-49a3-c530-a501ead42f2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier Accuracy: 0.924054990211054\n"
     ]
    }
   ],
   "source": [
    "# Multi-Layer Perceptron Classifier\n",
    "clf5 = MLPClassifier(random_state=42, max_iter=1000, hidden_layer_sizes=(128, 64))\n",
    "clf5.fit(X_train_scaled, y_train)  # requires scaled data\n",
    "mlp_preds = clf5.predict(X_val_scaled)\n",
    "mlp_acc = accuracy_score(y_val, mlp_preds)\n",
    "print(f'MLP Classifier Accuracy: {mlp_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OxnaeO1UHLXi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "id": "OxnaeO1UHLXi",
    "outputId": "dddca83e-8e3b-4504-9411-c374bcdc0650"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [05:18:27] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='mlogloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost\n",
    "clf6 = XGBClassifier(\n",
    "    n_estimators=200, learning_rate=0.1, max_depth=6,\n",
    "    random_state=42, use_label_encoder=False, eval_metric=\"mlogloss\"\n",
    ")\n",
    "clf6.fit(X_train_scaled, y_train_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gH7hMlIwIVdP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gH7hMlIwIVdP",
    "outputId": "d074383c-41e0-47b7-feec-7260385f2fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8394612852563413\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Validation and Test Accuracies\n",
    "val_accuracy = clf6.score(X_val_scaled, y_val_adjusted)\n",
    "print(\"Validation Accuracy:\", val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l3Osfw-zKcuT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3Osfw-zKcuT",
    "outputId": "7238db0d-2f03-4689-978e-fc0f6111d971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models have been saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# i had full Ram issues so i needed to train models oneby one and save to pkl\n",
    "joblib.dump(clf1, 'random_forest.pkl')\n",
    "joblib.dump(clf3, 'svc.pkl')\n",
    "joblib.dump(clf4, 'sgd.pkl')\n",
    "joblib.dump(clf5, 'mlp.pkl')\n",
    "joblib.dump(clf6, 'xgboost.pkl')\n",
    "\n",
    "print(\"Models have been saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3a0eaa",
   "metadata": {
    "id": "bb3a0eaa"
   },
   "source": [
    "## 1.4. Ensembling\n",
    "#### Create a hard and soft voting classifier using the models you have trained. You can use VotingClassifier. Check its performance on the validation set. Do you get better or worse performance than any of the individual classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b40O5noLTta",
   "metadata": {
    "id": "5b40O5noLTta"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# et_clf = joblib.load('extra_trees.pkl')\n",
    "# this model was way more huge about 4 gb so i could not use it :(\n",
    "rf_clf = joblib.load('random_forest.pkl')\n",
    "svc_clf = joblib.load('svc.pkl')\n",
    "sgd_clf = joblib.load('sgd.pkl')\n",
    "mlp_clf = joblib.load('mlp.pkl')\n",
    "xgb_clf = joblib.load('xgboost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KfIx-4ddrbN3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KfIx-4ddrbN3",
    "outputId": "98ab1d28-374a-42b1-d8d3-e574100f7f4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [05:26:45] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Voting Classifier Validation Accuracy: 0.9377917858910092\n"
     ]
    }
   ],
   "source": [
    "# Soft Voting Classifier\n",
    "voting_clf_soft = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_clf),\n",
    "        ('xgb', xgb_clf),\n",
    "        ('mlp', mlp_clf)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "voting_clf_soft.fit(X_train_scaled, y_train_adjusted)\n",
    "\n",
    "soft_preds = voting_clf_soft.predict(X_val_scaled)\n",
    "soft_acc = accuracy_score(y_val_adjusted, soft_preds)\n",
    "print(f'Soft Voting Classifier Validation Accuracy: {soft_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pd-4HDiNwl9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pd-4HDiNwl9a",
    "outputId": "d52806eb-bb20-4190-fe4f-483af0531ba3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:17] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Classifier Validation Accuracy: 0.853649878444956\n"
     ]
    }
   ],
   "source": [
    "# Hard Voting Classifier\n",
    "voting_clf_hard = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_clf),\n",
    "        ('xgb', xgb_clf),\n",
    "        ('svc', svc_clf),\n",
    "        ('sgd', sgd_clf),\n",
    "        ('mlp', mlp_clf)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_clf_hard.fit(X_train_scaled, y_train_adjusted)\n",
    "\n",
    "hard_preds = voting_clf_hard.predict(X_val_scaled)\n",
    "hard_acc = accuracy_score(y_val_adjusted, hard_preds)\n",
    "print(f'Hard Voting Classifier Validation Accuracy: {hard_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aJhq9sEcLdk5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aJhq9sEcLdk5",
    "outputId": "725facf5-472c-4050-dbcd-db7e1415863f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Set Accuracy (Hard Voting): 0.8552360954536458\n",
      "Final Test Set Accuracy (Soft Voting): 0.9381857611249279\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on the test set\n",
    "final_preds_hard = voting_clf_hard.predict(X_test_scaled)\n",
    "final_acc_hard = accuracy_score(y_test_adjusted, final_preds_hard)\n",
    "print(f'Final Test Set Accuracy (Hard Voting): {final_acc_hard}')\n",
    "\n",
    "final_preds_soft = voting_clf_soft.predict(X_test_scaled)\n",
    "final_acc_soft = accuracy_score(y_test_adjusted, final_preds_soft)\n",
    "print(f'Final Test Set Accuracy (Soft Voting): {final_acc_soft}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e59247",
   "metadata": {
    "id": "59e59247"
   },
   "source": [
    "#### Check if any of the models hurts the performance of the ensemble. You can access the estimators of the ensemble using estimators_ attribute. If so, drop those using set_params and reevaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VhudcRk2dXJM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VhudcRk2dXJM",
    "outputId": "99ea941a-0b37-45c9-b32e-bad4279a162d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Voting Validation Accuracy (3 models): 0.9203760676405413\n",
      "Hard Voting Validation Accuracy (all models): 0.7160129945569157\n"
     ]
    }
   ],
   "source": [
    "# NOTE: since training takes 1 hour each time i am bored sory:( so i will check manually\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# For soft voting, only 3 models will be included\n",
    "rf_probs = rf_clf.predict_proba(X_val_scaled)  # Random Forest (probabilities)\n",
    "xgb_probs = xgb_clf.predict_proba(X_val_scaled)  # XGBoost (probabilities)\n",
    "mlp_probs = mlp_clf.predict_proba(X_val_scaled)  # MLP (probabilities)\n",
    "\n",
    "# For hard voting, we will include all models so...\n",
    "svc_hard_preds = svc_clf.predict(X_val_scaled)  # SVC (hard predictions)\n",
    "sgd_hard_preds = sgd_clf.predict(X_val_scaled)  # SGD (hard predictions)\n",
    "\n",
    "\n",
    "all_probs_soft = [rf_probs, xgb_probs, mlp_probs]\n",
    "model_names_soft = ['rf', 'xgb', 'mlp']\n",
    "\n",
    "\n",
    "all_probs_hard = [\n",
    "    np.argmax(rf_probs, axis=1),  # Random Forest (hard predictions from probs)\n",
    "    np.argmax(xgb_probs, axis=1),  # XGBoost (hard predictions from probs)\n",
    "    np.argmax(mlp_probs, axis=1),  # MLP (hard predictions from probs)\n",
    "    svc_hard_preds,  # SVC\n",
    "    sgd_hard_preds,  # SGD\n",
    "]\n",
    "\n",
    "# Soft Voting (only 3 models)\n",
    "combined_probs_soft = np.mean(all_probs_soft, axis=0)\n",
    "soft_preds = np.argmax(combined_probs_soft, axis=1)\n",
    "soft_acc = accuracy_score(y_val_adjusted, soft_preds)\n",
    "print(f\"Soft Voting Validation Accuracy (3 models): {soft_acc}\")\n",
    "\n",
    "# Hard Voting (all models)\n",
    "all_hard_preds = np.array(all_probs_hard).T  # Transpose for mode calculation\n",
    "hard_preds = mode(all_hard_preds, axis=1).mode.flatten()\n",
    "hard_acc = accuracy_score(y_val_adjusted, hard_preds)\n",
    "print(f\"Hard Voting Validation Accuracy (all models): {hard_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M2F-3rn-Mkwv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2F-3rn-Mkwv",
    "outputId": "d6af6e1b-96be-42f4-fbf6-639a1afd3537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Soft Voting Evaluation Without Each Model:\n",
      "Soft Voting Validation Accuracy without rf: 0.9234525935328414\n",
      "Soft Voting Validation Accuracy without xgb: 0.9234310793657624\n",
      "Soft Voting Validation Accuracy without mlp: 0.8194315957057723\n",
      "\n",
      "Hard Voting Evaluation Without Each Model:\n",
      "Hard Voting Validation Accuracy without rf: 0.8148705922850197\n",
      "Hard Voting Validation Accuracy without xgb: 0.4925130698565005\n",
      "Hard Voting Validation Accuracy without mlp: 0.49274972569436976\n",
      "Hard Voting Validation Accuracy without svc: 0.8760676405412965\n",
      "Hard Voting Validation Accuracy without sgd: 0.8756481142832555\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "soft_probs = [rf_probs, xgb_probs, mlp_probs]\n",
    "soft_model_names = ['rf', 'xgb', 'mlp']\n",
    "\n",
    "\n",
    "hard_preds = [\n",
    "    np.argmax(rf_probs, axis=1),  # Random Forest (hard predictions from probs)\n",
    "    np.argmax(xgb_probs, axis=1),  # XGBoost (hard predictions from probs)\n",
    "    np.argmax(mlp_probs, axis=1),  # MLP (hard predictions from probs)\n",
    "    svc_clf.predict(X_val_scaled),  # SVC (hard predictions)\n",
    "    sgd_clf.predict(X_val_scaled),  # SGD (hard predictions)\n",
    "]\n",
    "hard_model_names = ['rf', 'xgb', 'mlp', 'svc', 'sgd']\n",
    "hard_preds = np.array(hard_preds).T  # Combining hard predictions for mode\n",
    "\n",
    "# Evaluating Soft Voting Without Each Model\n",
    "print(\"\\nSoft Voting Evaluation Without Each Model:\")\n",
    "for i, name in enumerate(soft_model_names):\n",
    "    # Excluding one model's probabilities\n",
    "    reduced_soft_probs = [p for j, p in enumerate(soft_probs) if j != i]\n",
    "    combined_reduced_probs = np.mean(reduced_soft_probs, axis=0)\n",
    "    soft_reduced_preds = np.argmax(combined_reduced_probs, axis=1)\n",
    "    soft_reduced_acc = accuracy_score(y_val_adjusted, soft_reduced_preds)\n",
    "    print(f\"Soft Voting Validation Accuracy without {name}: {soft_reduced_acc}\")\n",
    "\n",
    "# Evaluating Hard Voting Without Each Model\n",
    "print(\"\\nHard Voting Evaluation Without Each Model:\")\n",
    "for i, name in enumerate(hard_model_names):\n",
    "    # Excluding one model's predictions\n",
    "    reduced_hard_preds = np.delete(hard_preds, i, axis=1)\n",
    "    hard_reduced_preds = mode(reduced_hard_preds, axis=1).mode.flatten()\n",
    "    hard_reduced_acc = accuracy_score(y_val_adjusted, hard_reduced_preds)\n",
    "    print(f\"Hard Voting Validation Accuracy without {name}: {hard_reduced_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee18c22b",
   "metadata": {
    "id": "ee18c22b"
   },
   "source": [
    "# 2. Random Forest\n",
    "#### In this assignment, you are expected to build a random forest that classifies a toy dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b436fb8e",
   "metadata": {
    "id": "b436fb8e"
   },
   "source": [
    "## 2.1. Load dataset\n",
    "#### You will need to read the data from the file (data.csv). It contains 15000 samples and two features for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b69b32",
   "metadata": {
    "id": "87b69b32"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data.csv', header=None)\n",
    "data.columns = ['x1', 'x2', 'z']\n",
    "\n",
    "# Converting scientific notation to float and map 'z' to 0 or 1\n",
    "data['z'] = data['z'].astype(float) / 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0947a961",
   "metadata": {
    "id": "0947a961"
   },
   "source": [
    "## 2.2. Prepare dataset\n",
    "#### Split the data into train and test sets with 0.2 test size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120b11fd",
   "metadata": {
    "id": "120b11fd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data[['x1', 'x2']]\n",
    "y = data['z']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5e4122",
   "metadata": {
    "id": "6d5e4122"
   },
   "source": [
    "## 2.3. Modeling\n",
    "#### Train a DecisionTreeClassifier on the data. Use GridSearchCV to tune the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057e4beb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "057e4beb",
    "outputId": "e3af6b25-0fd8-4e23-9f67-9310218d14a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c1ab53",
   "metadata": {
    "id": "22c1ab53"
   },
   "source": [
    "#### Train the best model on the whole train set (do you need to?) and evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a9e15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f2a9e15",
    "outputId": "0969e40e-b89d-49d7-d4ee-ad69d4e1608a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy with the best model: 0.8556666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy with the best model:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758136a4",
   "metadata": {
    "id": "758136a4"
   },
   "source": [
    "#### Generate 1,200 subsets of the training set, each containing 100 randomly chosen instances. You can use ShuffleSplit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62be875",
   "metadata": {
    "id": "c62be875"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "ss = ShuffleSplit(n_splits=1200, train_size=100, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d537aa",
   "metadata": {
    "id": "64d537aa"
   },
   "source": [
    "#### Train one tree on each subset, using the best model you previously found. Evaluate the performance of the trees using the test set. Did you get lower or higher accuracy? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6c08ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f6c08ad",
    "outputId": "5c25752b-fb07-4838-c79e-509ce79ee613"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1200it [00:07, 155.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy over 1,200 trees: 0.7957122222222223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for train_index, _ in tqdm(ss.split(X_train)):\n",
    "    X_subset = X_train.iloc[train_index]\n",
    "    y_subset = y_train.iloc[train_index]\n",
    "\n",
    "\n",
    "    clf = DecisionTreeClassifier(**grid_search.best_params_, random_state=42)\n",
    "    clf.fit(X_subset, y_subset)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "print(\"Average accuracy over 1,200 trees:\", np.mean(accuracies))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01475c22",
   "metadata": {
    "id": "01475c22"
   },
   "source": [
    "#### For each instance in the test set, predict its class using 1200 trees, and keep only the most frequent prediction. You can use mode from scipy.stats. Evaluate these predictions. Did you get lower or higher accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FCgvAqIV0Xne",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FCgvAqIV0Xne",
    "outputId": "0a2c9631-e3f4-4a70-87b6-9031da3d48b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1200it [00:06, 188.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble test set accuracy: 0.857\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "for train_index, _ in tqdm(ss.split(X_train)):\n",
    "    X_subset = X_train.iloc[train_index]\n",
    "    y_subset = y_train.iloc[train_index]\n",
    "\n",
    "    clf = DecisionTreeClassifier(**grid_search.best_params_, random_state=42)\n",
    "    clf.fit(X_subset, y_subset)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    all_predictions.append(y_pred)\n",
    "\n",
    "all_predictions = np.array(all_predictions)  # Shape: (1200, number of test instances)\n",
    "\n",
    "ensemble_predictions = mode(all_predictions, axis=0).mode[0]\n",
    "ensemble_predictions = mode(all_predictions, axis=0)[0].squeeze()\n",
    "\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(\"Ensemble test set accuracy:\", ensemble_accuracy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
